GEMINI_SUPPORTED_MODELS = [
    "gemini-1.5-flash",
    "gemini-1.5-pro",
    "gemini-1.0",
]


def gemini_generate(api_key: str, model: str, prompt: str, system_prompt: str):
    """
    Generate a response using a Gemini language model.

    This function calls the Gemini API (via Google GenAI client) to generate
    a response based on the given user prompt and system prompt.

    Args:
        api_key (str): API key for authenticating with the Gemini API.
        model (str): Name of the Gemini model to use (must be in GEMINI_SUPPORTED_MODELS).
        prompt (str): The user input or query to send to the model.
        system_prompt (str): System-level instructions to guide model behavior.

    Returns:
        dict: A dictionary containing:
            - 'provider' (str): The model provider, always "gemini".
            - 'model' (str): The model used.
            - 'response' (str): The text response generated by the model.

    Raises:
        ImportError: If `google-genai` is not installed.
        Exception: If the API call fails for any reason.
    """

    try:
        from google import genai
    except ImportError:
        raise ImportError("Install: pip install google-genai")

    client = genai.Client(api_key=api_key)

    chat = client.chats.create(model=model)
    response = chat.send_message(
        f"System: {system_prompt}\nUser: {prompt}"
    )

    return {
        "provider": "gemini",
        "model": model,
        "response": response.text
    }
