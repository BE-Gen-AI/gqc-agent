{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3534df6f",
   "metadata": {},
   "source": [
    "# Example: How to Use the AgentPipeline to Run the Full GQC Workflow\n",
    "\n",
    "This code shows how to use the gqc_agent package to run the complete GQC pipeline.\n",
    "You only need to create an AgentPipeline object with your API key and LLM model.\n",
    "After that, you can call .run_gqc() to process the entire conversation through all internal agents.\n",
    "\n",
    "## How to Use ?\n",
    "\n",
    "- Import the AgentPipeline class from the package\n",
    "\n",
    "- Create a class instance\n",
    "\n",
    "- Provide your API key\n",
    "\n",
    "- Choose the model you want to use (must be a supported GPT)\n",
    "\n",
    "- Choose the provider name (must be gpt or gemini)\n",
    "\n",
    "- Prepare the user input structure\n",
    "\n",
    "  - input: current raw input\n",
    "\n",
    "  - current: current message with role + timestamp\n",
    "\n",
    "  - history: previous user + assistant messages\n",
    "\n",
    "- Call client.run_gqc()\n",
    "\n",
    "Print the final AI response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7101f0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'gpt-4o-mini' is valid for GPT client\n",
      "{'intent': 'search', 'rephrased_queries': ['Provide more details about the pending broker.', 'Explain the pending broker further.'], 'notes': \"The user is seeking more detailed information about the 'pending broker' in the TR Treaty module. Previous responses mentioned its usage but did not provide further context or explanation. The next response should elaborate on the role of the pending broker, its functions, and any relevant examples or scenarios where it is applied.\"}\n"
     ]
    }
   ],
   "source": [
    "from gqc_agent.core.orchestrator import AgentPipeline\n",
    "\n",
    "OPENAI_API_KEY = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "client = AgentPipeline(api_key=OPENAI_API_KEY, model=\"gpt-4o-mini\", provider=\"gpt\")\n",
    "response = client.run_gqc(\n",
    "    user_input = {\n",
    "        \"input\": \"Tell me more about it\",\n",
    "        \"current\": {\"role\": \"user\", \"query\": \"Tell me more about it\", \"timestamp\": \"2025-01-01 12:30:45\"},\n",
    "        \"history\": [\n",
    "            {\"role\": \"user\", \"query\": \"How are you doing today?\", \"timestamp\": \"2025-01-01 12:00:00\"},\n",
    "            {\"role\": \"assistant\", \"response\": \"i am fine, how about you? how can I assist you today?\", \"timestamp\": \"2025-01-01 12:01:10\"},\n",
    "            {\"role\": \"user\", \"query\": \"where pending broker is used?\", \"timestamp\": \"2025-01-01 12:02:00\"},\n",
    "            {\"role\": \"assistant\", \"response\": \"Pending broker is used in TR Treaty module\", \"timestamp\": \"2025-01-01 12:03:22\"}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5605489a",
   "metadata": {},
   "source": [
    "# Example: How to Use the AgentPipeline to Run the Full GQC Workflow\n",
    "\n",
    "This code shows how to use the gqc_agent package to run the complete GQC pipeline.\n",
    "You only need to create an AgentPipeline object with your API key and LLM model.\n",
    "After that, you can call .run_gqc() to process the entire conversation through all internal agents.\n",
    "\n",
    "## How to Use ?\n",
    "\n",
    "- Import the AgentPipeline class from the package\n",
    "\n",
    "- Create a class instance\n",
    "\n",
    "- Provide your API key\n",
    "\n",
    "- Choose the model you want to use (must be a supported Gemini model)\n",
    "\n",
    "- Choose the provider name (must be gpt or gemini)\n",
    "\n",
    "- Prepare the user input structure\n",
    "\n",
    "  - input: current raw input\n",
    "\n",
    "  - current: current message with role + timestamp\n",
    "\n",
    "  - history: previous user + assistant messages\n",
    "\n",
    "- Call client.run_gqc()\n",
    "\n",
    "Print the final AI response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0c6e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'models/gemini-2.5-flash' is valid for Gemini client\n",
      "{'intent': 'tool_call', 'rephrased_queries': [\"Set the description for the 'medical' department to 'related to handle medicine'.\", \"Assign 'related to handle medicine' as the description for the medical department.\"], 'notes': \"The user's current input is 'description of the department is 'related to handle medicine''. This is a direct follow-up to the initial request to add a department named 'medical'. The first assistant response asked for 'description, and active status' to add the department. The user has now provided the description. The 'active status' is still missing. The conversation history had a tangent about PHP, which should be ignored for the current task. The next response should confirm the department name and description, and prompt for the missing 'active status'.\"}\n"
     ]
    }
   ],
   "source": [
    "from gqc_agent.core.orchestrator import AgentPipeline\n",
    "\n",
    "GEMINI_API_KEY = \"YOUR_GEMINI_API_KEY\"\n",
    "\n",
    "client = AgentPipeline(api_key=GEMINI_API_KEY, model=\"models/gemini-2.5-flash\", provider=\"gemini\")\n",
    "response = client.run_gqc(\n",
    "    user_input = {\n",
    "        \"input\": \"description of the department is 'related to handle medicine'\",\n",
    "        \"current\": {\"role\": \"user\", \"query\": \"description of the department is 'related to handle medicine'\", \"timestamp\": \"2025-01-01 12:30:45\"},\n",
    "        \"history\": [\n",
    "            {\"role\": \"user\", \"query\": \"i want to add department with the name medical\", \"timestamp\": \"2025-01-01 12:00:00\"},\n",
    "            {\"role\": \"assistant\", \"response\": \"department name is medical, but provide me the description, and active status to add department.\", \"timestamp\": \"2025-01-01 12:01:10\"},\n",
    "            {\"role\": \"user\", \"query\": \"Is PHP still useful?\", \"timestamp\": \"2025-01-01 12:02:00\"},\n",
    "            {\"role\": \"assistant\", \"response\": \"Yes, PHP is still widely used, especially for WordPress and backend APIs.\", \"timestamp\": \"2025-01-01 12:03:22\"}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a7d3eb",
   "metadata": {},
   "source": [
    "# Example: How to List Supported GPT Models Using AgentPipeline\n",
    "\n",
    "This code shows how to use the gqc_agent package to check which GPT models are available with your API key.\n",
    "You only need to call the class method get_supported_models() from AgentPipeline.\n",
    "\n",
    "## How to Use ?\n",
    "\n",
    "- Import the AgentPipeline class from the package\n",
    "\n",
    "- Create a class instance\n",
    "\n",
    "- Provide your valid OpenAI API key\n",
    "\n",
    "- Choose the provider name (must be gpt or gemini)\n",
    "\n",
    "- Call AgentPipeline.get_supported_models(api_key=...)\n",
    "\n",
    "- Print the list of supported GPT models\n",
    "\n",
    "This is helpful for verifying which models your API key can access before running the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2786e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Models from AgentPipeline: ['gpt-4-0613', 'gpt-4', 'gpt-3.5-turbo', 'gpt-audio-mini-2025-12-15', 'gpt-4o-mini-transcribe-2025-03-20', 'gpt-4o-mini-tts-2025-03-20', 'gpt-4o-mini-tts-2025-12-15', 'gpt-realtime-mini-2025-12-15', 'davinci-002', 'babbage-002', 'gpt-3.5-turbo-instruct', 'gpt-3.5-turbo-instruct-0914', 'dall-e-3', 'dall-e-2', 'gpt-4-1106-preview', 'gpt-3.5-turbo-1106', 'tts-1-hd', 'tts-1-1106', 'tts-1-hd-1106', 'text-embedding-3-small', 'text-embedding-3-large', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-3.5-turbo-0125', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4o', 'gpt-4o-2024-05-13', 'gpt-4o-mini-2024-07-18', 'gpt-4o-mini', 'gpt-4o-2024-08-06', 'chatgpt-4o-latest', 'gpt-4o-audio-preview', 'gpt-4o-realtime-preview', 'omni-moderation-latest', 'omni-moderation-2024-09-26', 'gpt-4o-realtime-preview-2024-12-17', 'gpt-4o-audio-preview-2024-12-17', 'gpt-4o-mini-realtime-preview-2024-12-17', 'gpt-4o-mini-audio-preview-2024-12-17', 'o1-2024-12-17', 'o1', 'gpt-4o-mini-realtime-preview', 'gpt-4o-mini-audio-preview', 'computer-use-preview', 'o3-mini', 'o3-mini-2025-01-31', 'gpt-4o-2024-11-20', 'computer-use-preview-2025-03-11', 'gpt-4o-search-preview-2025-03-11', 'gpt-4o-search-preview', 'gpt-4o-mini-search-preview-2025-03-11', 'gpt-4o-mini-search-preview', 'gpt-4o-transcribe', 'gpt-4o-mini-transcribe', 'o1-pro-2025-03-19', 'o1-pro', 'gpt-4o-mini-tts', 'o3-2025-04-16', 'o4-mini-2025-04-16', 'o3', 'o4-mini', 'gpt-4.1-2025-04-14', 'gpt-4.1', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-mini', 'gpt-4.1-nano-2025-04-14', 'gpt-4.1-nano', 'gpt-image-1', 'codex-mini-latest', 'gpt-4o-realtime-preview-2025-06-03', 'gpt-4o-audio-preview-2025-06-03', 'o4-mini-deep-research', 'gpt-4o-transcribe-diarize', 'o4-mini-deep-research-2025-06-26', 'gpt-5-chat-latest', 'gpt-5-2025-08-07', 'gpt-5', 'gpt-5-mini-2025-08-07', 'gpt-5-mini', 'gpt-5-nano-2025-08-07', 'gpt-5-nano', 'gpt-audio-2025-08-28', 'gpt-realtime', 'gpt-realtime-2025-08-28', 'gpt-audio', 'gpt-5-codex', 'gpt-image-1-mini', 'gpt-5-pro-2025-10-06', 'gpt-5-pro', 'gpt-audio-mini', 'gpt-audio-mini-2025-10-06', 'gpt-5-search-api', 'gpt-realtime-mini', 'gpt-realtime-mini-2025-10-06', 'sora-2', 'sora-2-pro', 'gpt-5-search-api-2025-10-14', 'gpt-5.1-chat-latest', 'gpt-5.1-2025-11-13', 'gpt-5.1', 'gpt-5.1-codex', 'gpt-5.1-codex-mini', 'gpt-5.1-codex-max', 'gpt-5.2-2025-12-11', 'gpt-5.2', 'gpt-5.2-pro-2025-12-11', 'gpt-5.2-pro', 'gpt-5.2-chat-latest', 'gpt-4o-mini-transcribe-2025-12-15', 'gpt-3.5-turbo-16k', 'tts-1', 'whisper-1', 'text-embedding-ada-002']\n"
     ]
    }
   ],
   "source": [
    "from gqc_agent.core.orchestrator import AgentPipeline\n",
    "\n",
    "OPENAI_API_KEY = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "client = AgentPipeline(api_key=OPENAI_API_KEY, model=\"gpt-4o-mini\", provider=\"gpt\")\n",
    "gpt_models = client.get_supported_models()\n",
    "print(\"GPT Models from AgentPipeline:\", gpt_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94711de9",
   "metadata": {},
   "source": [
    "# Example: How to List Supported Gemini Models Using AgentPipeline\n",
    "\n",
    "This code shows how to use the gqc_agent package to check which Gemini models are available with your API key.\n",
    "You only need to call the class method get_supported_models() from AgentPipeline.\n",
    "\n",
    "## How to Use ?\n",
    "\n",
    "- Import the AgentPipeline class from the package\n",
    "\n",
    "- Create a class instance\n",
    "\n",
    "- Provide your valid GEMINI API key\n",
    "\n",
    "- Choose the provider name (must be gpt or gemini)\n",
    "\n",
    "- Call AgentPipeline.get_supported_models(api_key=...)\n",
    "\n",
    "- Print the list of supported Gemini models\n",
    "\n",
    "This is helpful for verifying which models your API key can access before running the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8534b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Models from AgentPipeline: ['models/embedding-gecko-001', 'models/gemini-2.5-flash', 'models/gemini-2.5-pro', 'models/gemini-2.0-flash-exp', 'models/gemini-2.0-flash', 'models/gemini-2.0-flash-001', 'models/gemini-2.0-flash-exp-image-generation', 'models/gemini-2.0-flash-lite-001', 'models/gemini-2.0-flash-lite', 'models/gemini-2.0-flash-lite-preview-02-05', 'models/gemini-2.0-flash-lite-preview', 'models/gemini-exp-1206', 'models/gemini-2.5-flash-preview-tts', 'models/gemini-2.5-pro-preview-tts', 'models/gemma-3-1b-it', 'models/gemma-3-4b-it', 'models/gemma-3-12b-it', 'models/gemma-3-27b-it', 'models/gemma-3n-e4b-it', 'models/gemma-3n-e2b-it', 'models/gemini-flash-latest', 'models/gemini-flash-lite-latest', 'models/gemini-pro-latest', 'models/gemini-2.5-flash-lite', 'models/gemini-2.5-flash-image-preview', 'models/gemini-2.5-flash-image', 'models/gemini-2.5-flash-preview-09-2025', 'models/gemini-2.5-flash-lite-preview-09-2025', 'models/gemini-3-pro-preview', 'models/gemini-3-pro-image-preview', 'models/nano-banana-pro-preview', 'models/gemini-robotics-er-1.5-preview', 'models/gemini-2.5-computer-use-preview-10-2025', 'models/deep-research-pro-preview-12-2025', 'models/embedding-001', 'models/text-embedding-004', 'models/gemini-embedding-exp-03-07', 'models/gemini-embedding-exp', 'models/gemini-embedding-001', 'models/aqa', 'models/imagen-4.0-generate-preview-06-06', 'models/imagen-4.0-ultra-generate-preview-06-06', 'models/imagen-4.0-generate-001', 'models/imagen-4.0-ultra-generate-001', 'models/imagen-4.0-fast-generate-001', 'models/veo-2.0-generate-001', 'models/veo-3.0-generate-001', 'models/veo-3.0-fast-generate-001', 'models/veo-3.1-generate-preview', 'models/veo-3.1-fast-generate-preview', 'models/gemini-2.5-flash-native-audio-latest', 'models/gemini-2.5-flash-native-audio-preview-09-2025', 'models/gemini-2.5-flash-native-audio-preview-12-2025']\n"
     ]
    }
   ],
   "source": [
    "from gqc_agent.core.orchestrator import AgentPipeline\n",
    "\n",
    "GEMINI_API_KEY = \"YOUR_GEMINI_API_KEY\"\n",
    "\n",
    "client = AgentPipeline(api_key=GEMINI_API_KEY, model=\"models/gemini-2.5-flash\", provider=\"gemini\")\n",
    "gemini_models = client.get_supported_models()\n",
    "print(\"Gemini Models from AgentPipeline:\", gemini_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd29fbd1",
   "metadata": {},
   "source": [
    "# Example: How to View a query_rephrasor agent System Prompt File\n",
    "\n",
    "This code shows how to use the gqc_agent package to load and display any system prompt stored inside the system_prompts directory.\n",
    "The show_system_prompt() class method reads the file and returns its full content as plain text.\n",
    "\n",
    "## How to Use ?\n",
    "\n",
    "- Import the AgentPipeline class\n",
    "\n",
    "- Call AgentPipeline.show_system_prompt()\n",
    "\n",
    "- Provide the filename of a system prompt (e.g., \"query_rephraser.md\")\n",
    "\n",
    "- Print the file content to see the full system prompt\n",
    "\n",
    "This is helpful when you want to understand or debug how an agent behaves internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8ca8eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available system prompts: You are a query rephraser assistant.\n",
      "\n",
      "- Look at the current query and previous history user queries.\n",
      "- Rephrase the current query into two clear and concise versions.\n",
      "- Preserve the original user intent or action in the rephrased queries.\n",
      "- Use the history queries as context if relevant.\n",
      "- If the current query is part of an ongoing task from previous queries, keep the rephrased queries focused on completing that task.\n",
      "- Do NOT automatically turn statements into questions.\n",
      "- Return only JSON in this exact format:\n",
      "{\"rephrased_queries\": [\"Option 1\", \"Option 2\"]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gqc_agent.core.orchestrator import AgentPipeline\n",
    "\n",
    "prompts = AgentPipeline.show_system_prompt(filename=\"query_rephraser.md\")\n",
    "print(\"Available system prompts:\", prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f41e95",
   "metadata": {},
   "source": [
    "# Example: How to View a note_creator agent System Prompt File\n",
    "\n",
    "This code shows how to use the gqc_agent package to load and display any system prompt stored inside the system_prompts directory.\n",
    "The show_system_prompt() class method reads the file and returns its full content as plain text.\n",
    "\n",
    "## How to Use ?\n",
    "\n",
    "- Import the AgentPipeline class\n",
    "\n",
    "- Call AgentPipeline.show_system_prompt()\n",
    "\n",
    "- Provide the filename of a system prompt (e.g., \"note_creator.md\")\n",
    "\n",
    "- Print the file content to see the full system prompt\n",
    "\n",
    "This is helpful when you want to understand or debug how an agent behaves internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354252f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available system prompts: You are an advanced note creation assistant.\n",
      "\n",
      "Task:\n",
      "- Read the current user input and the full conversation history.\n",
      "- Create a detailed note that explains:\n",
      "    - The user’s intent.\n",
      "    - What previous responses have already covered.\n",
      "    - What is missing or needs elaboration.\n",
      "- Provide context so the next response can be complete and helpful.\n",
      "- Always return output in JSON with a single key \"notes\".\n",
      "- Do not include greetings, explanations, or text outside the JSON.\n",
      "\n",
      "Example format:\n",
      "{\n",
      "  \"notes\": \"The user asked for more detailed information. Previous responses covered some points, but did not provide full context or examples. Include missing context and elaborate where needed.\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gqc_agent.core.orchestrator import AgentPipeline\n",
    "\n",
    "prompts = AgentPipeline.show_system_prompt(filename=\"note_creator.md\")\n",
    "print(\"Available system prompts:\", prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024679ff",
   "metadata": {},
   "source": [
    "# Example: How to View a intent_classifier agent System Prompt File\n",
    "\n",
    "This code shows how to use the gqc_agent package to load and display any system prompt stored inside the system_prompts directory.\n",
    "The show_system_prompt() class method reads the file and returns its full content as plain text.\n",
    "\n",
    "## How to Use ?\n",
    "\n",
    "- Import the AgentPipeline class\n",
    "\n",
    "- Call AgentPipeline.show_system_prompt()\n",
    "\n",
    "- Provide the filename of a system prompt (e.g., \"intent_classifier.md\")\n",
    "\n",
    "- Print the file content to see the full system prompt\n",
    "\n",
    "This is helpful when you want to understand or debug how an agent behaves internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8d6c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available system prompts: You are an Intent Classifier for a multi-agent AI system.\n",
      "\n",
      "Rules:\n",
      "\n",
      "1. Analyze the previous history **user queries** (ignore assistant responses) and the current query to understand context.\n",
      "\n",
      "2. Determine the intent:\n",
      "   - greeting → ONLY if the current input is a **pure greeting** or a **simple greeting reply**\n",
      "      AND it contains:\n",
      "        • NO question\n",
      "        • NO request for help or assistance\n",
      "        • NO task, action, or instruction\n",
      "        • NO continuation of a previous discussion\n",
      "        • NO additional intent beyond greeting\n",
      "\n",
      "    If the input contains ANY question word, request, explanation, or conversational follow-up, it MUST NOT be classified as `greeting`.\n",
      "   - search → the user is asking for **information, instructions, examples, or explanations**.\n",
      "   - tool_call → the user intends to **perform an action immediately** (like adding, updating, deleting, creating, or executing a tool/task).\n",
      "   - ambiguous → the query is unclear, incomplete, or needs clarification.\n",
      "\n",
      "3. Question vs Action:\n",
      "   - If the current query is phrased as a **question**, or starts with words like \"how\", \"what\", \"steps\", \"example of\", classify it as `search` even if it contains action keywords.\n",
      "   - Only classify as `tool_call` if the user explicitly intends to perform the action, or the query **logically continues a previous tool_call task**.\n",
      "\n",
      "4. Context-aware reasoning:\n",
      "   - If previous user queries indicate an ongoing task and the current query is related to completing that task, classify as `tool_call`.\n",
      "   - Otherwise, if the current query is asking for instructions, explanations, or information, classify as `search`.\n",
      "\n",
      "5. Return the output ONLY in this JSON format:\n",
      "\n",
      "{\n",
      "  \"intent\": \"greeting\"\n",
      "}\n",
      "\n",
      "OR\n",
      "\n",
      "{\n",
      "  \"intent\": \"search\"\n",
      "}\n",
      "\n",
      "OR\n",
      "\n",
      "{\n",
      "  \"intent\": \"tool_call\"\n",
      "}\n",
      "\n",
      "OR\n",
      "\n",
      "{\n",
      "  \"intent\": \"ambiguous\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gqc_agent.core.orchestrator import AgentPipeline\n",
    "\n",
    "prompts = AgentPipeline.show_system_prompt(filename=\"intent_classifier.md\")\n",
    "print(\"Available system prompts:\", prompts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
